---
phase: 04-voice-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - voice_agent.py
autonomous: true

must_haves:
  truths:
    - "User speaks French and STT transcribes correctly (Whisper with language param)"
    - "Agent responds in French with natural TTS voice (Piper siwis-medium for FR)"
    - "Wake greeting plays in configured language"
    - "Agent system prompt is loaded in configured language"
    - "English-only installations continue working without changes"
  artifacts:
    - path: "voice_agent.py"
      provides: "Language-aware STT, TTS, wake greetings, and prompt loading"
      contains: "PIPER_VOICE_MAP"
  key_links:
    - from: "voice_agent.py"
      to: "src/caal/settings.py"
      via: "load_prompt_with_context(language=language)"
      pattern: "load_prompt_with_context.*language"
    - from: "voice_agent.py"
      to: "groq STT constructor"
      via: "language parameter"
      pattern: "groq_plugin\\.STT.*language"
    - from: "voice_agent.py"
      to: "openai STT constructor"
      via: "language parameter"
      pattern: "openai\\.STT.*language"
---

<objective>
Wire the language setting through the voice pipeline: STT language parameter, TTS voice mapping per language, localized wake greetings, and language-aware prompt loading.

Purpose: This connects the language infrastructure (Phase 1) and localized prompts (Plan 01) to the actual voice pipeline, so users hear and speak in their configured language.
Output: Updated voice_agent.py with full language awareness
</objective>

<execution_context>
@/Users/mmaudet/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mmaudet/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-voice-pipeline/04-RESEARCH.md
@.planning/phases/04-voice-pipeline/04-01-SUMMARY.md
@voice_agent.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add language-aware STT, TTS, and wake greetings</name>
  <files>voice_agent.py</files>
  <action>
**Step 1: Add language constants near the top of the file (after the config section, around line 98)**

```python
# Per-language voice and greeting mappings
PIPER_VOICE_MAP = {
    "en": "speaches-ai/piper-en_US-ryan-high",
    "fr": "speaches-ai/piper-fr_FR-siwis-medium",
}

DEFAULT_WAKE_GREETINGS = {
    "en": [
        "Hey, what's up?",
        "Hi there!",
        "Yeah?",
        "What can I do for you?",
        "Hey!",
        "Yo!",
        "What's up?",
    ],
    "fr": [
        "Salut, quoi de neuf ?",
        "Bonjour !",
        "Oui ?",
        "Qu'est-ce que je peux faire pour toi ?",
        "Salut !",
        "Yo !",
        "Quoi de neuf ?",
    ],
}
```

**Step 2: Read language in `get_runtime_settings()` (around line 104)**

Add `language` to the returned dict:
```python
return {
    # Language
    "language": settings.get("language", "en"),
    # ... existing settings ...
}
```

**Step 3: Update `load_prompt()` function (around line 142)**

Update to accept and pass language:
```python
def load_prompt(language: str = "en") -> str:
    """Load and populate prompt template with date context."""
    return settings_module.load_prompt_with_context(
        timezone_id=TIMEZONE_ID,
        timezone_display=TIMEZONE_DISPLAY,
        language=language,
    )
```

**Step 4: Update VoiceAssistant.__init__ (around line 306)**

Change `instructions=load_prompt()` to accept language. Add a `language` parameter to VoiceAssistant.__init__:
```python
def __init__(
    self,
    caal_llm: CAALLLM,
    language: str = "en",
    ...
) -> None:
    super().__init__(
        instructions=load_prompt(language=language),
        llm=caal_llm,
    )
```

**Step 5: Update STT construction in `entrypoint()` (around line 466-477)**

Read language from runtime settings and pass to STT:
```python
language = runtime["language"]

# Build STT
if runtime["stt_provider"] == "groq":
    base_stt = groq_plugin.STT(
        model="whisper-large-v3-turbo",
        language=language,
    )
else:
    base_stt = openai.STT(
        base_url=f"{SPEACHES_URL}/v1",
        api_key="not-needed",
        model=WHISPER_MODEL,
        language=language,
    )
```

**Step 6: Update TTS construction in `entrypoint()` (around line 552-568)**

For Piper, select voice based on language. For Kokoro with French, auto-switch to Piper with a log warning:
```python
# Create TTS instance based on provider
tts_provider = runtime["tts_provider"]

# Auto-switch from Kokoro to Piper for non-English languages (Kokoro has limited multilingual support)
if tts_provider == "kokoro" and language != "en":
    logger.warning(
        f"Kokoro TTS has limited {language} support, auto-switching to Piper"
    )
    tts_provider = "piper"

if tts_provider == "piper":
    # Select Piper voice based on language, fall back to English
    piper_voice = PIPER_VOICE_MAP.get(language, PIPER_VOICE_MAP["en"])
    tts_instance = openai.TTS(
        base_url=f"{SPEACHES_URL}/v1",
        api_key="not-needed",
        model=piper_voice,
        voice="default",
    )
else:
    tts_instance = openai.TTS(
        base_url=f"{KOKORO_URL}/v1",
        api_key="not-needed",
        model=TTS_MODEL,
        voice=runtime["tts_voice_kokoro"],
    )
```

Note: When auto-switching to Piper, use `PIPER_VOICE_MAP` (not `runtime["tts_voice_piper"]`) so the correct per-language voice is selected. If user has explicitly set `tts_voice_piper` in settings, that's the English default and shouldn't override the language-based selection.

**Step 7: Update wake greetings in `entrypoint()` (around line 493)**

Replace:
```python
wake_greetings = all_settings.get("wake_greetings", ["Hey, what's up?"])
```
With language-aware greeting selection:
```python
# Use user's custom greetings if set in settings.json, otherwise use per-language defaults
user_settings = settings_module.load_user_settings()
if "wake_greetings" in user_settings:
    wake_greetings = user_settings["wake_greetings"]
else:
    wake_greetings = DEFAULT_WAKE_GREETINGS.get(language, DEFAULT_WAKE_GREETINGS["en"])
```

**Step 8: Pass language to VoiceAssistant constructor (around line 644)**

```python
assistant = VoiceAssistant(
    caal_llm=caal_llm,
    language=language,
    ...
)
```

**Step 9: Update startup logging (around line 440-464)**

Add language to the startup log block:
```python
logger.info(f"  Language: {language}")
```
Also update STT log line to show the language:
```python
if runtime["stt_provider"] == "groq":
    logger.info(f"  STT: Groq (whisper-large-v3-turbo, lang={language})")
else:
    logger.info(f"  STT: {SPEACHES_URL} ({WHISPER_MODEL}, lang={language})")
```

**Step 10: Update webhook "wake" action (around line 686-690)**

The webhook wake action also needs language-aware greetings:
```python
elif action == "wake":
    user_settings_wh = settings_module.load_user_settings()
    if "wake_greetings" in user_settings_wh:
        greetings = user_settings_wh["wake_greetings"]
    else:
        lang = settings_module.get_setting("language", "en")
        greetings = DEFAULT_WAKE_GREETINGS.get(lang, DEFAULT_WAKE_GREETINGS["en"])
    greeting = random.choice(greetings)
    await session.say(greeting)
```
Note: `import random` is already present in the wake word section (line 488). Make sure it's accessible here too -- it's imported inside an `if wake_word_enabled:` block, so move the `import random` to the top-level imports or ensure it's imported in the webhook handler scope as well.
  </action>
  <verify>
1. Run linter: `uv run ruff check voice_agent.py`
2. Run type checker: `uv run mypy voice_agent.py --ignore-missing-imports` (may have pre-existing issues, just verify no NEW errors)
3. Verify the file parses without syntax errors: `uv run python -c "import voice_agent; print('OK')"`
4. Spot-check key patterns exist:
   ```
   grep -n "PIPER_VOICE_MAP" voice_agent.py
   grep -n "DEFAULT_WAKE_GREETINGS" voice_agent.py
   grep -n 'language=' voice_agent.py
   grep -n "load_prompt_with_context" voice_agent.py
   ```
  </verify>
  <done>
- STT constructors (both Groq and Speaches) receive language parameter from settings
- TTS Piper voice is selected based on language via PIPER_VOICE_MAP
- Kokoro auto-switches to Piper for non-English languages with log warning
- Wake greetings are selected per language (with user override preserved)
- load_prompt() passes language to load_prompt_with_context()
- VoiceAssistant receives and uses language for prompt loading
- Startup logging shows configured language and STT language param
- Webhook wake action uses language-aware greetings
- All existing English-only behavior is preserved when language="en"
  </done>
</task>

</tasks>

<verification>
1. `uv run ruff check voice_agent.py` passes
2. `uv run python -c "import voice_agent"` succeeds without errors
3. PIPER_VOICE_MAP contains "en" and "fr" entries
4. DEFAULT_WAKE_GREETINGS contains "en" and "fr" entries
5. STT constructors use `language=language` (not hardcoded "en")
6. Piper TTS uses `PIPER_VOICE_MAP.get(language, ...)` (not hardcoded model)
7. Wake greeting selection checks user_settings first, then falls back to per-language defaults
8. `load_prompt()` passes `language` parameter through to `load_prompt_with_context()`
</verification>

<success_criteria>
- grep confirms `language=language` in both STT constructors (groq and openai)
- grep confirms `PIPER_VOICE_MAP.get(language` in TTS section
- grep confirms `DEFAULT_WAKE_GREETINGS.get(language` in wake greeting section
- grep confirms `load_prompt_with_context.*language` in load_prompt function
- No hardcoded `language="en"` in STT constructors
- File passes ruff linter
- File imports and parses without errors
</success_criteria>

<output>
After completion, create `.planning/phases/04-voice-pipeline/04-02-SUMMARY.md`
</output>
